#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Fix All Pages Properly - ã™ã¹ã¦ã®ãƒšãƒ¼ã‚¸ã‚’æ­£ã—ãä¿®æ­£
"""

import os
import sys
import json
import time
import re
from typing import List, Dict, Any

try:
    from notion_client import Client
    from notion_client.errors import APIResponseError, RequestTimeoutError
except Exception:
    print("notion-client ãŒã‚ã‚Šã¾ã›ã‚“ã€‚`pip install -r requirements.txt` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    sys.exit(1)

from dotenv import load_dotenv
load_dotenv()

# ç’°å¢ƒå¤‰æ•°
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
CHATGPT_DB_ID = os.getenv("CHATGPT_DB_ID")
NOTION_TIMEOUT = int(os.getenv("NOTION_TIMEOUT", "60"))

if not NOTION_TOKEN or not CHATGPT_DB_ID:
    print("ç’°å¢ƒå¤‰æ•° NOTION_TOKEN / CHATGPT_DB_ID ãŒæœªè¨­å®šã§ã™ã€‚.env ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    sys.exit(1)

# Notionã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
notion = Client(auth=NOTION_TOKEN, timeout_ms=int(NOTION_TIMEOUT * 1000))

def with_retry(fn, *, max_attempts=4, base_delay=1.0, what="api"):
    """ãƒªãƒˆãƒ©ã‚¤ä»˜ãAPIå‘¼ã³å‡ºã—"""
    import random
    attempt = 0
    while True:
        try:
            return fn()
        except RequestTimeoutError as e:
            attempt += 1
            if attempt >= max_attempts:
                raise
            delay = base_delay * (2 ** (attempt-1)) + random.uniform(0, 0.5)
            print(f"[RETRY] Timeout on {what}. retry {attempt}/{max_attempts} in {delay:.1f}s")
            time.sleep(delay)
        except APIResponseError as e:
            if getattr(e, "code", "") == "rate_limited":
                attempt += 1
                retry_after = float(getattr(e, "headers", {}).get("Retry-After", 1)) if hasattr(e, "headers") else 1.0
                delay = max(retry_after, base_delay * (2 ** (attempt-1))) + random.uniform(0, 0.5)
                print(f"[RETRY] rate_limited on {what}. retry {attempt}/{max_attempts} in {delay:.1f}s")
                time.sleep(delay)
                if attempt < max_attempts:
                    continue
            raise

def clean_garbage_text_comprehensive(text: str) -> str:
    """åŒ…æ‹¬çš„ãªã‚´ãƒŸæ–‡å­—é™¤å»ï¼ˆæ”¹è¡Œã¯ä¿æŒï¼‰"""
    # æ§˜ã€…ãªã‚´ãƒŸæ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»
    patterns_to_remove = [
        # åŸºæœ¬çš„ãªã‚´ãƒŸæ–‡å­—
        r'â¬›â–¶ï¸citeâ­turn0search\d+â—€ï¸â¬›',  # â¬›â–¶ï¸citeâ­turn0search0â—€ï¸â¬› ãªã©
        r'â¬›âš«',  # â¬›âš«
        r'â–¶ï¸.*?â¬›â—€ï¸',  # â–¶ï¸...â¬›â—€ï¸ ã§å›²ã¾ã‚ŒãŸéƒ¨åˆ†
        r'â–¶ï¸',  # å˜ç‹¬ã®â–¶ï¸
        r'â¬›',  # å˜ç‹¬ã®â¬›
        r'â—€ï¸',  # å˜ç‹¬ã®â—€ï¸
        r'âš«',  # å˜ç‹¬ã®âš«
        r'cite',  # citeæ–‡å­—åˆ—
        r'turn0search\d+',  # turn0search0, turn0search1 ãªã©
        r'â­',  # â­
        r'citeâ­',  # citeâ­
        r'â­turn0search\d+',  # â­turn0search0 ãªã©
        r'\*\*\.\*',  # **.** ãƒ‘ã‚¿ãƒ¼ãƒ³
        r'_\s*\*\*\.\*',  # _ **.** ãƒ‘ã‚¿ãƒ¼ãƒ³
        
        # è¿½åŠ ã®ã‚´ãƒŸæ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³
        r'video',  # videoæ–‡å­—åˆ—
        r'turn\d+search\d+',  # turn1search14 ãªã©
        r'search\d+',  # search14 ãªã©
        r'turn\d+',  # turn1 ãªã©
        
        # ç‰¹æ®Šãªç©ºç™½æ–‡å­—ã‚„åˆ¶å¾¡æ–‡å­—
        r'[\u200B-\u200D\uFEFF]',  # ã‚¼ãƒ­å¹…æ–‡å­—
        r'[\u2060-\u2064\u206A-\u206F]',  # ãã®ä»–ã®åˆ¶å¾¡æ–‡å­—
        r'[\ue200-\ue2ff]',  # åˆ¶å¾¡æ–‡å­—ï¼ˆ\ue200ãªã©ï¼‰
        
        # ä¸è¦ãªè¨˜å·ã®çµ„ã¿åˆã‚ã›
        r'[â¬›âš«â–¶ï¸â—€ï¸]+',  # è¤‡æ•°ã®è¨˜å·ã®é€£ç¶š
    ]
    
    cleaned_text = text
    for pattern in patterns_to_remove:
        cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE)
    
    # æ”¹è¡Œã‚’ä¿æŒã—ãªãŒã‚‰ã€éåº¦ãªç©ºç™½è¡Œã®ã¿ã‚’æ•´ç†
    cleaned_text = re.sub(r'\n\s*\n\s*\n+', '\n\n', cleaned_text)
    
    # è¡Œé ­è¡Œæœ«ã®ç©ºç™½ã‚’é™¤å»ï¼ˆæ”¹è¡Œã¯ä¿æŒï¼‰
    cleaned_text = re.sub(r'^\s+|\s+$', '', cleaned_text, flags=re.MULTILINE)
    
    # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«çµ±ä¸€ï¼ˆæ”¹è¡Œã¯ä¿æŒï¼‰
    cleaned_text = re.sub(r'[ \t]+', ' ', cleaned_text)
    
    return cleaned_text.strip()

def format_content_with_proper_newlines(content: str) -> str:
    """é©åˆ‡ãªæ”¹è¡Œå‡¦ç†ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’åˆ†é›¢
    content = re.sub(r'(ğŸ“Š ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: \d+)(ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼)', r'\1\n\n\2', content)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®é–“ã«æ”¹è¡Œã‚’è¿½åŠ 
    content = re.sub(r'(ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼[^ã€‘]*ã€‘)([^ã€\n])', r'\1\n\2', content)
    content = re.sub(r'(ã€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ[^ã€‘]*ã€‘)([^ã€\n])', r'\1\n\2', content)
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åŒºåˆ‡ã‚Šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã¦ã€é©åˆ‡ãªæ”¹è¡Œã‚’è¿½åŠ 
    section_patterns = [
        r'^é›»è»Šã§ã®ç§»å‹•:$',
        r'^è»Šã§ã®ç§»å‹•:$',
        r'^æ³¨æ„ç‚¹:$',
        r'^[^:]+:$',
    ]
    
    lines = content.split('\n')
    formatted_lines = []
    
    for i, line in enumerate(lines):
        line = line.strip()
        if not line:
            formatted_lines.append('')
            continue
            
        formatted_lines.append(line)
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åŒºåˆ‡ã‚Šã®å‰å¾Œã«è¿½åŠ ã®æ”¹è¡Œã‚’æŒ¿å…¥
        is_section = any(re.match(pattern, line) for pattern in section_patterns)
        if is_section:
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åŒºåˆ‡ã‚Šã®å‰ã«æ”¹è¡Œã‚’è¿½åŠ 
            if i > 0 and lines[i-1].strip():
                formatted_lines.insert(-1, '')
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åŒºåˆ‡ã‚Šã®å¾Œã«æ”¹è¡Œã‚’è¿½åŠ 
            if i < len(lines) - 1 and lines[i+1].strip():
                formatted_lines.append('')
    
    return '\n'.join(formatted_lines)

def find_page_by_title(title: str) -> str:
    """ã‚¿ã‚¤ãƒˆãƒ«ã§ãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢"""
    try:
        response = with_retry(
            lambda: notion.databases.query(
                database_id=CHATGPT_DB_ID,
                filter={
                    "property": "åå‰",
                    "title": {
                        "equals": title
                    }
                }
            ),
            what="find page"
        )
        
        results = response.get("results", [])
        if results:
            return results[0]["id"]
        return None
        
    except Exception as e:
        print(f"ãƒšãƒ¼ã‚¸æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def delete_page(page_id: str) -> bool:
    """ãƒšãƒ¼ã‚¸ã‚’å‰Šé™¤ï¼ˆã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼‰"""
    try:
        with_retry(
            lambda: notion.pages.update(
                page_id=page_id,
                archived=True
            ),
            what="delete page"
        )
        return True
    except Exception as e:
        print(f"ãƒšãƒ¼ã‚¸å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def create_page_with_proper_formatting(title: str, content_data: Dict[str, Any]) -> str:
    """é©åˆ‡ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ãƒšãƒ¼ã‚¸ã‚’ä½œæˆ"""
    try:
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
        content = content_data.get("content", "")
        
        # ã‚´ãƒŸæ–‡å­—ã‚’é™¤å»
        cleaned_content = clean_garbage_text_comprehensive(content)
        
        # é©åˆ‡ãªæ”¹è¡Œå‡¦ç†
        formatted_content = format_content_with_proper_newlines(cleaned_content)
        
        # æ”¹è¡Œã‚’æ˜ç¤ºçš„ã«å‡¦ç†
        lines = formatted_content.split('\n')
        children = []
        
        for line in lines:
            line = line.strip()
            if line:  # ç©ºã§ãªã„è¡Œ
                children.append({
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [
                            {
                                "type": "text",
                                "text": {
                                    "content": line
                                }
                            }
                        ]
                    }
                })
            else:  # ç©ºè¡Œï¼ˆæ”¹è¡Œï¼‰ã¯å¿…ãšè¿½åŠ 
                children.append({
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": []
                    }
                })
        
        # ãƒšãƒ¼ã‚¸ä½œæˆ
        response = with_retry(
            lambda: notion.pages.create(
                parent={"database_id": CHATGPT_DB_ID},
                properties={
                    "åå‰": {
                        "title": [
                            {
                                "type": "text",
                                "text": {
                                    "content": title
                                }
                            }
                        ]
                    }
                },
                children=children
            ),
            what="create page"
        )
        
        return response.get("id")
        
    except Exception as e:
        print(f"ãƒšãƒ¼ã‚¸ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def load_backup_data(filename: str) -> List[Dict[str, Any]]:
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=== ã™ã¹ã¦ã®ãƒšãƒ¼ã‚¸ã‚’æ­£ã—ãä¿®æ­£ ===")
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
    backup_files = [f for f in os.listdir('.') if f.startswith('pages_backup_') and f.endswith('.json')]
    
    if not backup_files:
        print("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
    
    # æœ€æ–°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
    backup_file = sorted(backup_files)[-1]
    print(f"ä½¿ç”¨ã™ã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«: {backup_file}")
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    backup_data = load_backup_data(backup_file)
    if not backup_data:
        print("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return
    
    print(f"ä¿®æ­£å¯¾è±¡ãƒšãƒ¼ã‚¸æ•°: {len(backup_data)}")
    print()
    
    # æ—¢ã«æ­£ã—ãä¿®æ­£ã•ã‚Œã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚­ãƒƒãƒ—
    skip_titles = ["æ¨ªé ˆè³€ å¸¸å…‰å¯º ãƒ«ãƒ¼ãƒˆ", "ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãææ¡ˆ", "Conversation Summary"]
    
    fixed_count = 0
    failed_count = 0
    skipped_count = 0
    
    for i, page_data in enumerate(backup_data, 1):
        title = page_data.get("title", f"ãƒšãƒ¼ã‚¸ {i}")
        
        # æ—¢ã«æ­£ã—ãä¿®æ­£ã•ã‚Œã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if title in skip_titles:
            print(f"[{i}/{len(backup_data)}] ã‚¹ã‚­ãƒƒãƒ—: {title} (æ—¢ã«ä¿®æ­£æ¸ˆã¿)")
            skipped_count += 1
            continue
        
        print(f"[{i}/{len(backup_data)}] ä¿®æ­£ä¸­: {title}")
        
        # æ—¢å­˜ã®ãƒšãƒ¼ã‚¸ã‚’å‰Šé™¤
        existing_page_id = find_page_by_title(title)
        if existing_page_id:
            print(f"  æ—¢å­˜ã®ãƒšãƒ¼ã‚¸ã‚’å‰Šé™¤ä¸­...")
            if delete_page(existing_page_id):
                print(f"  ãƒšãƒ¼ã‚¸ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                time.sleep(1)  # å‰Šé™¤ã®åæ˜ ã‚’å¾…ã¤
            else:
                print(f"  ãƒšãƒ¼ã‚¸ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ")
                failed_count += 1
                continue
        
        # æ–°ã—ã„ãƒšãƒ¼ã‚¸ã‚’ä½œæˆ
        print(f"  æ–°ã—ã„ãƒšãƒ¼ã‚¸ã‚’ä½œæˆä¸­...")
        new_page_id = create_page_with_proper_formatting(title, page_data)
        
        if new_page_id:
            print(f"  ãƒšãƒ¼ã‚¸ã‚’ä½œæˆã—ã¾ã—ãŸ: {new_page_id}")
            fixed_count += 1
        else:
            print(f"  ãƒšãƒ¼ã‚¸ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
            failed_count += 1
        
        # APIåˆ¶é™ã‚’é¿ã‘ã‚‹
        time.sleep(0.5)
        
        # é€²æ—è¡¨ç¤ºï¼ˆ10ãƒšãƒ¼ã‚¸ã”ã¨ï¼‰
        if i % 10 == 0:
            print(f"  é€²æ—: {i}/{len(backup_data)} ãƒšãƒ¼ã‚¸å®Œäº†")
    
    print()
    print("=== ä¿®æ­£å®Œäº† ===")
    print(f"ä¿®æ­£ã—ãŸãƒšãƒ¼ã‚¸æ•°: {fixed_count}")
    print(f"å¤±æ•—ã—ãŸãƒšãƒ¼ã‚¸æ•°: {failed_count}")
    print(f"ã‚¹ã‚­ãƒƒãƒ—ã—ãŸãƒšãƒ¼ã‚¸æ•°: {skipped_count}")
    
    if fixed_count > 0:
        print("âœ… ä¿®æ­£æˆåŠŸï¼ã™ã¹ã¦ã®ãƒšãƒ¼ã‚¸ãŒæ­£ã—ãä¿®æ­£ã•ã‚Œã¾ã—ãŸã€‚")
        print("Notionã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        print("âŒ ä¿®æ­£å¤±æ•—ã€‚å•é¡Œã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
